{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHEN Zhexiao, LACOSTE Lucille, QUILLERIET Marie-Clémentine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet numérique : câble sous-marin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie théorique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le théorème du cours autorisant l'approximation évoquée est la loi forte des grands nombres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prend $Z_{2}=(Z(x_{j_{1}}),...,Z(x_{j_{n}}))$ et $Z_{1}= Z/Z_{2}$\n",
    "Alors la loi conditionnelle du vecteur des composantes de Z correspondant aux points de discrétisation sans observation, connaissant les valeur prises par les composantes aux sites d'observations est:\n",
    "    $$f_{Z_{1}|Z_{2}=(z(x_{j_{1}}),...,z(x_{j_{n}}))}=\\frac{1}{(2\\pi)^{\\frac{N-n+2}{2}}}\\times\\exp(-\\frac{1}{2}(z_{1}-\\psi(z_{2}))^{t}CS_{z_{2}}^{-1}(z_{1}-\\psi(z_{2})))$$\n",
    "avec :\n",
    "    $$CS_{Z_{1}}=C_{1}-C_{Z_{1},Z_{2}}C_{Z_{2}}^{-1}C_{Z_{2},Z_{1}}$$\n",
    "    $$\\psi(z_{2})=m_{Z_{1}}+C_{Z_{1},Z_{2}}C_{Z_{2}}^{-1}(z_{2}-m_{Z_{2}})$$\n",
    "Et on a :\n",
    "    $$E(Z_{1}|Z_{2})=m_{Z_{1}}+C_{Z_{1},Z_{2}}C_{Z_{2}}^{-1}(Z_{2}-m_{Z_{2}})$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a :\n",
    "    $$R.Y=[\\sum_{k=1}^{p}r_{ik}Y_{k}]_{i\\in[1,p]}$$\n",
    "    $$Z=[\\sum_{k=1}^{p}r_{ik}Y_{k}+m_{i}]_{i\\in[1,p]}$$\n",
    "Donc chaque terme de Z sont une combinaison linéaire des variables aléatoires gaussiennes, alors Z est un vecteur gaussien à densité. Il faut juste calculer les covariances, alors:\n",
    "    $$Cov(Z_{i},Z_{j})=E((Z_{i}-m_{i})(Z_{j}-m_{j}))=E(\\sum_{k=1}^{p}r_{ik}Y_{k}\\sum_{l=1}^{p}r_{jl}Y_{l})=\\sum_{l,k}r_{ik}r_{jl}\\times E(Y_{k}Y_{l})$$\n",
    "Or, quand $k \\not= l$,\n",
    "    $$E(Y_{k}\\times Y_{l}))=\\int\\int y_{1}y_{2}\\frac{1}{2\\pi}\\exp^{-\\frac{y_{1}^{2}+y_{2}^{2}}{2}}dy_{1}dy_{2}=\\frac{1}{2\\pi} \\times (\\int y\\exp^{-\\frac{y^{2}}{2}}dy)^{2} = 0 $$\n",
    "Alors,\n",
    "    $$Cov(Z_{i},Z_{j})=\\sum_{l,k}r_{ik}r_{jl}\\times E(Y_{k}^{2})=\\sum_{l,k}r_{ik}r_{jl} \\times 1$$\n",
    "Finalement, la matrice de covariance est:\n",
    "    $$C=R.R^{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme $ Z1|Z2 = m_{Z1|Z2} + RY $, avec $ C_{Z1|Z2} = R^tR $ et $ Y $ un vecteur à composantes suivant des lois gaussiennes centrées réduites indépendantes :\n",
    "\n",
    "1. on calcule $ R $ et $ m_{Z1|Z2} $ (qui ne varient pas selon la simulation)\n",
    "\n",
    "2. puis on simule Y. La simulation de Y se fait grâce au fait que toute variable aléatoire $X$ telle que $ X = \\sqrt{-2ln(U)}cos(2\\pi V) $, avec $U$ et $V$ deux lois uniformes indépendantes sur $]0,1[$, suive une loi normale centrée réduite. Le but est donc d'écrire $Y$ comme $ Y = \\sqrt{-2ln(U)}cos(2\\pi V) $ et de simuler $U$ et $V$ grâce au module numpy.random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "A = 0\n",
    "B = 500\n",
    "N = 101\n",
    "Delta = (B-A)/(N-1)\n",
    "discretization_indexes = np.arange(N)\n",
    "discretization = discretization_indexes*Delta\n",
    "\n",
    "mu = -5\n",
    "a = 50\n",
    "sigma2 = 12\n",
    "\n",
    "observation_indexes = np.array([0, 20, 40, 60, 80, 100])\n",
    "observation_discretization = observation_indexes*Delta\n",
    "depth = np.array([0, -4, -12.8, -1, -6.5, 0])\n",
    "unknown_indexes = np.array(list(set(discretization_indexes)-set(observation_indexes)))\n",
    "unknown_discretization = unknown_indexes*Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule la covariance en distinguant selon que la distance donnée est un scalaire ou une matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(dist, a, sigma2):\n",
    "    C = lambda h: sigma2*np.exp(-np.abs(h)/a)\n",
    "    if type(dist) == np.ndarray:\n",
    "        n = dist.shape[0]\n",
    "        m = dist.shape[1]\n",
    "        Cov = np.zeros((n,m))\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                Cov[i,j] = C(dist[i,j])\n",
    "        return Cov\n",
    "    else:\n",
    "        return C(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_dist(discretization):\n",
    "    Dist = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            Dist[i,j] = np.abs(discretization[i]-discretization[j])\n",
    "    return Dist\n",
    "\n",
    "mat_dist(discretization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_z(discretization, a, sigma2):\n",
    "    return covariance(mat_dist(discretization), a, sigma2)\n",
    "\n",
    "covariance_z(discretization, a, sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons essayé une première méthode : calculer la covariance de Z puis extraire les sous matrices demandées. Cependant, cela prenait trop de temps donc nous avons décidé de calculer, pour chaque sous matrice, la sous matrice de distance correspondante puis de calculer la sous-matrice elle-même comme précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Covariance(Z2, Z2)\n",
    "\n",
    "def mat_dist_obs(observation_discretization):\n",
    "    n = len(observation_discretization)\n",
    "    Dist = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            Dist[i,j] = np.abs(observation_discretization[i]-observation_discretization[j])\n",
    "    return Dist\n",
    "\n",
    "def cov_obs(observation_discretization, a, sigma2):\n",
    "    return covariance(mat_dist_obs(observation_discretization), a, sigma2)\n",
    "\n",
    "# 2. Covariance(Z1, Z2)\n",
    "\n",
    "def mat_dist_inc_obs(observation_discretization, unknown_discretization):\n",
    "    n = len(unknown_discretization)\n",
    "    m = len(observation_discretization)\n",
    "    Dist = np.zeros((n,m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            Dist[i,j] = np.abs(unknown_discretization[i]-observation_discretization[j])\n",
    "    return Dist\n",
    "\n",
    "def cov_inc_obs(observation_discretization, unknown_discretization, a, sigma2):\n",
    "    return covariance(mat_dist_inc_obs(observation_discretization, unknown_discretization), a, sigma2)\n",
    "\n",
    "# 3. Covariance(Z2, Z1)\n",
    "\n",
    "def mat_dist_obs_inc(observation_discretization, unknown_discretization):\n",
    "    n = len(observation_discretization)\n",
    "    m = len(unknown_discretization)\n",
    "    Dist = np.zeros((n,m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            Dist[i,j] = np.abs(observation_discretization[i]-unknown_discretization[j])\n",
    "    return Dist\n",
    "\n",
    "def cov_obs_inc(observation_discretization, unknown_discretization, a, sigma2):\n",
    "    return covariance(mat_dist_obs_inc(observation_discretization, unknown_discretization), a, sigma2)\n",
    "\n",
    "# 4. Covariance(Z1, Z1)\n",
    "\n",
    "def mat_dist_inc(unknown_discretization):\n",
    "    n = len(unknown_discretization)\n",
    "    Dist = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            Dist[i,j] = np.abs(unknown_discretization[i]-unknown_discretization[j])\n",
    "    return Dist\n",
    "\n",
    "def cov_inc(unknown_discretization, a, sigma2):\n",
    "    return covariance(mat_dist_inc(unknown_discretization), a, sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la formule du cours:\n",
    "$ E(Z1|Z2) = m_{Z1} + C_{Z1,Z2}C_{Z2}^{-1}(Z2 - m_{Z2}) $, sachant que selon l'énoncé, les $m_{Z1}$ et $m_{Z2}$ sont des vecteurs constitués uniquement de $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esp_conditionnelle(observation_indexes, unknown_indexes, observation_discretization, unknown_discretization, depth, a ,sigma2):\n",
    "    esp_obs = np.array([mu for i in observation_indexes])\n",
    "    esp_inc = np.array([mu for i in unknown_indexes])\n",
    "    depth = np.array(depth)\n",
    "    inv_cov_obs = np.linalg.inv(cov_obs(observation_discretization, a ,sigma2))\n",
    "    produit1 = np.dot(inv_cov_obs, depth - esp_obs)\n",
    "    produit2 = np.dot(cov_inc_obs(observation_discretization, unknown_discretization, a ,sigma2), produit1)\n",
    "    return esp_inc + produit2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la formule du cours :\n",
    "$ Cov(Z1|Z2) = C_{Z1} - C_{Z1,Z2}C_{Z2}^{-1}C_{Z2,Z1} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_conditionnelle(observation_discretization, unknown_discretization, a ,sigma2): # cov(Z1|Z2)\n",
    "    C_z1 = cov_inc(unknown_discretization, a, sigma2)\n",
    "    C_z1_z2 = cov_inc_obs(observation_discretization, unknown_discretization, a ,sigma2)\n",
    "    C_z2_z1 = cov_obs_inc(observation_discretization, unknown_discretization, a ,sigma2)\n",
    "    inv_C_z2 = np.linalg.inv(cov_obs(observation_discretization, a ,sigma2))\n",
    "    produit1 = np.dot(inv_C_z2, C_z2_z1)\n",
    "    produit2 = np.dot(C_z1_z2, produit1)\n",
    "    return C_z1 - produit2\n",
    "\n",
    "n = len(unknown_indexes)\n",
    "diag = np.array([cov_conditionnelle(observation_discretization, unknown_discretization, a, sigma2)[i,i] for i in range(n)])\n",
    "plt.scatter(unknown_discretization, diag)\n",
    "plt.title(\"Variance conditionnelle\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que la variance conditionnelle fait des \"sauts de mouton\", en revenant à 0 aux points dont on connait la profondeur. C'est normal car plus on s'approche d'un point dont on connaît la profondeur (qu'on note $Z(x_{j_{i}})$), plus la covariance entre ce point et celui qui s'en approche est grande, i.e. plus les deux variables sont corrélées, à tel point qu'au bout d'un moment la variable aléatoire modélisant la profondeur du point qui s'approche de $Z(x_{j_{i}})$ se comporte presque comme une constante. Or la variance d'une constante est nulle, d'où la cohérence du résultat trouvé. \n",
    "\n",
    "La variance conditionnelle est donc maximale lorsque que l'on se place au milieu de deux points consécutifs dont on connait la profondeur, car c'est là que la variable aléatoire modélisant la profondeur est le plus décorrélée par rapport aux deux points dont on connait la profondeur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme $ Z_1|Z_2 = m_{Z_1|Z_2} + RY $, avec $ C_{Z_1|Z_2} = R^tR $, et $ Y $ un vecteur à composantes suivant des lois gaussiennes centrées réduites indépendantes, on calcule $ R $ et $ m_{Z_1|Z_2} $ (qui ne varient pas selon la simulation), puis on simule Y.\n",
    "\n",
    "La simulation de Y se fait grâce au fait que $ X = \\sqrt{-2ln(U)}cos(2\\pi V) $, avec $U$ et $V$ deux lois uniformes indépendantes sur $]0,1[$, suive une loi normale centrée réduite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R(C):\n",
    "    return np.linalg.cholesky(C)\n",
    "\n",
    "esp_cond = esp_conditionnelle(observation_indexes, unknown_indexes, observation_discretization, unknown_discretization, depth, a ,sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_loi_cond(unknown_indexes, observation_discretization, unknown_discretization, a ,sigma2):\n",
    "    n = len(unknown_indexes)\n",
    "    Y = []\n",
    "    for i in range(n):\n",
    "        yi = np.sqrt(-2*np.log(rd.random()))*np.cos(2*np.pi*rd.random())\n",
    "        Y.append(yi)\n",
    "    C = cov_conditionnelle(observation_discretization, unknown_discretization, a ,sigma2)\n",
    "    return esp_cond + np.dot(R(C), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On plotte ensuite le vecteur $ Z_1 $ des $z$ inconnus trouvés par simulation, et le vecteur $ Z_2 $ des $z$ déjà observés. On plotte également l'espérance conditionnelle de $ Z_1 $ sachant $ Z_2 $. Il faut voir si cette espérance est une bonne approximation de $ Z_1 $ trouvé par simulation, tout comme on approche $L$ par son espérance conditionnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(unknown_discretization, simulation_loi_cond(unknown_indexes, observation_discretization, unknown_discretization, a ,sigma2))\n",
    "plt.scatter(observation_discretization, depth)\n",
    "plt.scatter(unknown_discretization, esp_cond)\n",
    "plt.legend([\"simulation\", \"z observés\", \"espérance conditionnelle\"])\n",
    "plt.title(\"z simulés, données, espérance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que l'espérance conditionnelle colle avec les points dont on connaît la profondeur, ce qui est rassurant.\n",
    "Ensuite, on voit que l'allure de la courbe formée par les z simulés est grossièrement la même que celle donnée par l'espérance conditionnelle. On pourra donc, par la suite, approximer $Z$ par l'espérance conditionnelle de $Z_1|Z_2$, complétée par $Z_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer la longueur du câble à l'issue de la simulation, on utilise Pythagore :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longueur_cable(vect_depth, Delta):\n",
    "    n = len(vect_depth)\n",
    "    l = 0\n",
    "    for i in range(1,n):\n",
    "        l += np.sqrt((Delta)**2 + (vect_depth[i]-vect_depth[i-1])**2)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On approxime la longueur $L$ par l'espérance conditionnelle de $L$ sachant $ Z_{obs} $, elle-même approximée par une moyenne basique des longueurs trouvées au cours des 100 simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longueur_cable_simul(observation_indexes, unknown_indexes, Delta, N, observation_discretization, unknown_discretization, a ,sigma2, simul = 100):\n",
    "    S = 0\n",
    "    for k in range(simul):\n",
    "        Z_inc = simulation_loi_cond(unknown_indexes, observation_discretization, unknown_discretization, a ,sigma2)\n",
    "        Z = [0 for i in range(N)]\n",
    "        for i, item in enumerate(observation_indexes):\n",
    "            Z[item] = depth[i]\n",
    "        for i, item in enumerate(unknown_indexes):\n",
    "            Z[item] = Z_inc[i]\n",
    "        l_k = longueur_cable(Z,Delta)\n",
    "        S += l_k\n",
    "    return S/simul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre méthode pour approximer $L$ est d'approximer $Z$ par l'espérance conditionnelle de $ Z_{1} $ sachant $ Z_{2} $, complétée par les $z$ déjà connus. On remonte ensuite à $L$ avec Pythagore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longueur_esp_cond(observation_indexes, unknown_indexes, Delta, N):\n",
    "    Z = [0 for i in range(N)]\n",
    "    for i, item in enumerate(observation_indexes):\n",
    "        Z[item] = depth[i]\n",
    "    for i, item in enumerate(unknown_indexes):\n",
    "        Z[item] = esp_cond[i]\n",
    "    return longueur_cable(Z, Delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectue alors la comparaison entre les deux $L$ trouvés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(longueur_cable_simul(observation_indexes, unknown_indexes, Delta, N, observation_discretization, unknown_discretization, a ,sigma2, simul = 100), longueur_esp_cond(observation_indexes, unknown_indexes, Delta, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a une différence non négligeable d'environ $22-23 m$ (selon les simulations) entre les deux longueurs trouvées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_n = []\n",
    "n = np.arange(1,101,1)\n",
    "somme = 0\n",
    "for i in n:\n",
    "    somme += longueur_cable_simul(observation_indexes, unknown_indexes, Delta, N, observation_discretization, unknown_discretization, a ,sigma2, 1)\n",
    "    M_n.append(somme/i)\n",
    "plt.scatter(n, M_n)\n",
    "plt.title(\"Moyenne des longueurs des câbles en fonction du nombre de simulations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La moyenne fluctue lorsque l'on fait un petit nombre de simulations, mais se stabilise ensuite sur de grands nombres de simulations, ce qui est logique car faire un grand nombre de simulation permet normalement d'avoir une moyenne plus représentative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche l'histogramme des $ l_k $ générés sur $n$ simulations, avec $N$ points de discrétisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramme(observation_indexes, unknown_indexes, observation_discretization, unknown_discretization, Delta, N, n):\n",
    "    liste_lk = []\n",
    "    for k in range(n):\n",
    "        lk = longueur_cable_simul(observation_indexes, unknown_indexes, Delta, N, observation_discretization, unknown_discretization, a ,sigma2, simul = 1)\n",
    "        liste_lk.append(lk)\n",
    "    plt.bar([f\"l_{k}\" for k in range(n)], height = liste_lk)\n",
    "    plt.title(\"Histogramme des longueurs de câble générées\")\n",
    "    plt.show()\n",
    "\n",
    "histogramme(observation_indexes, unknown_indexes, observation_discretization, unknown_discretization, Delta, N, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Méthode 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons laissé cette méthode, mais pensons qu'elle est fausse car elle représente en réalité l'intervalle de confiance à $95\\%$ de la $\\textit {moyenne}$ des longueurs et non des longueurs elles-mêmes - c'est pourquoi l'intervalle trouvé est si petit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On  pose $ S_n = \\sum \\limits_{{k=0}}^n L_k $ et $ M_n = \\frac {S_n}{n} $. Comme les $ L_k $ sont indépendants, de même loi (de moyenne $m$ de de variance $\\sigma$) par théorème central limite, $ \\sqrt{n} \\frac {M_n - m}{\\sigma} \\sim N(0,1) $. Or l'intervalle de confiance à $95 \\% $ d'une loi normale centrée réduite est : $ ]-1.96 ; 1.96[ $. On note a = 1.96.\n",
    "\n",
    "$ Alors : \\\\\n",
    "P(\\sqrt{n} \\frac {M_n - m}{\\sigma} \\in ]-a ; a [) = 0.95 \\\\\n",
    "i.e. P(\\frac {M_n - m}{\\sigma} \\in ]\\frac {-a}{\\sqrt {n}} ; \\frac {a}{\\sqrt{n}} [) = 0.95 \\\\\n",
    "i.e. P(M_n - m \\in ]\\frac {-a \\sigma}{\\sqrt {n}} ; \\frac {a \\sigma}{\\sqrt{n}} [) = 0.95 \\\\\n",
    "i.e. P(M_n \\in ]\\frac {-a \\sigma}{\\sqrt {n}} + m ; \\frac {a \\sigma}{\\sqrt{n}} + m [) = 0.95 $\n",
    "\n",
    "Ainsi l'intervalle de confiance à $ 95\\% $ est donné par $ ]\\frac {-a \\sigma}{\\sqrt {n}} + m ; \\frac {a \\sigma}{\\sqrt{n}} + m [ $.\n",
    "\n",
    "On approche $m$ par la moyenne des $L_k$, où chaque $L_k$ est obtenu pendant la $k^{ième}$ simulation.\n",
    "\n",
    "Pour ce qui est du calcul de $\\sigma$ : comme $ \\sigma^2 = E((L_k - m)^2) $, pour $k \\in [0,n]$ on calcule $(L_k - m)^2$ puis on approxime l'espérance de cette quantité par sa moyenne sur les $n$ simulations réalisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des L_k\n",
    "\n",
    "liste_lk = []\n",
    "for k in range(100):\n",
    "    lk = longueur_cable_simul(observation_indexes, unknown_indexes, Delta, N, observation_discretization, unknown_discretization, a ,sigma2, simul = 1)\n",
    "    liste_lk.append(lk)\n",
    "liste_lk = np.array(liste_lk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervalle de confiance\n",
    "\n",
    "m = sum(liste_lk)/len(liste_lk)\n",
    "sigma = sum((liste_lk - m)**2)/len(liste_lk)\n",
    "borne_inf = -0.196*sigma + m\n",
    "borne_sup = 0.196*sigma + m\n",
    "print(f\"L'intervalle de confiance à 95% est ]{borne_inf}, {borne_sup}[\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Méthode 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois, on trie la liste de $L_k$ obtenus par simulation et on prend les $2/3^{ièmes}$ valeurs du début puis les $97/98^{ièmes}$ valeurs de fin pour être sûr que seuls $5$ valeurs sur $100$ (donc $5\\%$ des valeurs) n'appartiennent pas à cet intervalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_lk = sorted(liste_lk)\n",
    "borne_inf = (liste_lk[2]+liste_lk[3])/2\n",
    "borne_sup = (liste_lk[96]+liste_lk[97])/2\n",
    "print(f\"L'intervalle de confiance à 95% est ]{borne_inf}, {borne_sup}[.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On génère la liste des $L_k$ puis on compte le nombre de $L_k$ qui sont supérieurs à  $525m$, et on divise par le nombre de $L_k$ calculés pour avoir la probabilité voulue. \n",
    "\n",
    "On fait cette opération 5 fois puis on prend la moyenne des probabilités obtenues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_pba = []\n",
    "for i in range(5):\n",
    "    liste_lk = []\n",
    "    for k in range(100):\n",
    "        lk = longueur_cable_simul(observation_indexes, unknown_indexes, Delta, N, observation_discretization, unknown_discretization, a ,sigma2, simul = 1)\n",
    "        liste_lk.append(lk)\n",
    "    liste_lk = np.array(liste_lk)\n",
    "    pba = sum(liste_lk > 525)/100\n",
    "    liste_pba.append(pba)\n",
    "print(f\"La probabilité que la longueur du câble dépasse 525m est de {sum(liste_pba)/5}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons seulement fait le cas de 1000 simulations car le code mettait trop de temps à s'exécuter...nous n'avons pas réussi à trouver d'alternatives plus rapides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison entre les deux L trouvés (pour 1000 simulations cette fois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(longueur_cable_simul(observation_indexes, unknown_indexes, Delta, N, observation_discretization, unknown_discretization, a ,sigma2, simul = 1000), longueur_esp_cond(observation_indexes, unknown_indexes, Delta, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Représentation de la suite $M_n$ des moyennes des longueurs des câbles en fonction du nombre de simulations (jusqu'à 1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_n = []\n",
    "n = np.arange(1,1001,1)\n",
    "sum = 0\n",
    "for i in n:\n",
    "    sum += longueur_cable_simul(observation_indexes, unknown_indexes, Delta, N, observation_discretization, unknown_discretization, a ,sigma2, 1)\n",
    "    M_n.append(sum/i)\n",
    "plt.scatter(n, M_n)\n",
    "plt.title(\"Moyenne des longueurs des câbles en fonction du nombre de simulations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Représentation de l'histogramme des longueurs de câble générées sur 1000 simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramme(observation_indexes, unknown_indexes, observation_discretization, unknown_discretization, Delta, N, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul de l'intervalle de confiance à $95\\%$ de la longueur du câble, pour 1000 simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des L_k\n",
    "\n",
    "liste_lk = []\n",
    "for k in range(1000):\n",
    "    lk = longueur_cable_simul(observation_indexes, unknown_indexes, Delta, N, observation_discretization, unknown_discretization, a ,sigma2, simul = 1)\n",
    "    liste_lk.append(lk)\n",
    "liste_lk = np.array(liste_lk)\n",
    "\n",
    "# Intervalle de confiance\n",
    "\n",
    "liste_lk = sorted(liste_lk)\n",
    "borne_inf = (liste_lk[2]+liste_lk[3])/2\n",
    "borne_sup = (liste_lk[996]+liste_lk[997])/2\n",
    "print(f\"L'intervalle de confiance à 95% est ]{borne_inf}, {borne_sup}[\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul de l'estimation de la probabilité que la longueur du câble dépasse 525m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_pba = []\n",
    "for i in range(5):\n",
    "    liste_lk = []\n",
    "    for k in range(1000):\n",
    "        lk = longueur_cable_simul(observation_indexes, unknown_indexes, Delta, N, observation_discretization, unknown_discretization, a ,sigma2, simul = 1)\n",
    "        liste_lk.append(lk)\n",
    "    liste_lk = np.array(liste_lk)\n",
    "    pba = sum(liste_lk > 525)/1000\n",
    "    liste_pba.append(pba)\n",
    "print(f\"La probabilité que la longueur du câble dépasse 525m est de {sum(liste_pba)/5}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
